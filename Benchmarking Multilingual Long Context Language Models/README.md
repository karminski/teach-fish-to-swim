
# Benchmarking Multilingual Long-Context Language Models

## 论文信息

**标题**: One ruler to measure them all: Benchmarking multilingual long-context language models

**作者**: Yekyung Kim, Jenna Russell, Marzena Karpinska, Mohit Iyyer

**机构**: University of Maryland, Microsoft, UMass Amherst

**发表**: COLM 2025

## 核心贡献

本论文提出了 **ONERULER**，一个专门设计用于评估多语言长上下文语言模型的综合基准测试。这是首个大规模、系统性的多语言长上下文评估框架，具有以下特点：

- **26种语言**：涵盖高资源、中等资源和低资源语言
- **7个合成任务**：5个NIAH变体 + 2个聚合任务
- **4种上下文长度**：8K、32K、64K、128K tokens
- **6个主流模型**：包括开源和闭源模型
- **创新性设计**：引入"无针"（nonexistent needle）选项，更贴近真实场景

## 研究背景与动机

### 为什么需要多语言长上下文基准测试？

长上下文理解对于大语言模型的实际应用（如摘要生成、问答系统）至关重要。然而，现有的长上下文基准测试存在明显局限：

1. **语言单一性**：RULER等基准测试主要关注英语，少数基准只包含英语和中文
2. **缺乏多语言视角**：不清楚模型在多语言和跨语言长上下文场景中的表现
3. **任务过于简单**：传统NIAH任务假设答案总是存在，与真实场景不符

### ONERULER的设计目标

- 面向**指令微调后的模型**（与RULER针对基座模型不同）
- 引入**真实场景元素**：允许答案不存在
- 提供**公平的跨语言比较**：统一的100个名词翻译集合
- 揭示**语言资源差异**对长上下文能力的影响

## ONERULER 框架详解

### 测试任务设计

ONERULER包含**7种任务**，从简单检索到复杂聚合：

![ONERULER的七个任务](./assets/images/The%20seven%20tasks%20included%20in%20ONERULER.png)

#### 📍 检索任务（5种NIAH变体）

所有NIAH任务基于"海里捞针"范式，目标是从长文本中检索特定信息。

**1. Single-NIAH (S-NIAH) - 单针任务**
- **任务**：在长文本中找到一个目标句子，提取关键词对应的数字
- **特点**：经典NIAH任务，但允许答案不存在
- **提示模板关键点**：包含"If no such numbers exist, please answer 'none'"
- **难度**：基础任务，但none选项显著增加难度

**2. Multi-key NIAH (MK-NIAH) - 多键任务**
- **任务**：4个针插入文本，其中3个是干扰项，只有1个包含正确的key
- **目标**：识别包含目标key的针，返回对应value
- **难度**：需要区分干扰项

**3. Multi-value NIAH (MV-NIAH) - 多值任务**
- **任务**：4个针共享同一个key，但有不同的value
- **目标**：检索所有4个value
- **难度**：比MK-NIAH更难，模型容易提前终止或遗漏value

**4. Multi-query NIAH (MQ-NIAH) - 多查询任务**
- **任务**：与MK-NIAH结构相同，但包含多个查询
- **目标**：准确检索所有查询的信息
- **特点**：测试模型跨多个检索操作保持上下文感知的能力
- **有趣发现**：模型在MQ-NIAH上的表现竟然优于S-NIAH（非英语）

**5. None-NIAH (NONE-NIAH) - 无针任务**
- **任务**：文本中包含4个针，但都是干扰项，正确答案是"none"
- **目标**：识别答案不存在的情况
- **难度**：最难的NIAH任务，很多模型倾向于强行给出答案
- **创新性**：类似SQuAD 2.0引入不可回答问题的挑战

#### 📊 聚合任务（2种CWE变体）

与检索任务不同，聚合任务要求模型综合整个上下文信息。

**6. CWE-easy - 简单常见词提取**
- **任务**：从长词表中识别出现频率最高的10个词
- **参数**：最高频词出现30次，干扰词出现3次
- **难度**：短上下文简单，长上下文困难

**7. CWE-hard - 困难常见词提取**
- **任务**：与CWE-easy相同，但频率差距缩小
- **参数**：最高频词出现20次，干扰词出现10次
- **难度**：极难，所有模型准确率接近0%

### 语言覆盖（26种语言）

论文精心选择了26种语言，涵盖不同语系、书写系统和资源水平：

**高资源语言（22种）**：
- 斯拉夫语系：波兰语(pl)、俄语(ru)、乌克兰语(uk)、捷克语(cs)、塞尔维亚语(sr)
- 罗曼语系：法语(fr)、西班牙语(es)、意大利语(it)、葡萄牙语(pt)
- 日耳曼语系：英语(en)、德语(de)、荷兰语(nl)、瑞典语(sv)、挪威语(no)、丹麦语(da)
- 其他：中文(zh)、日语(ja)、韩语(ko)、波斯语(fa)、芬兰语(fi)、匈牙利语(hu)、越南语(vi)

**低资源语言（4种）**：
- 印地语(hi)、斯瓦希里语(sw)、泰米尔语(ta)、塞索托语(st)

**定义标准**：维基百科文章数量≥25万篇为高资源语言

### 数据收集方法

**指令翻译流程**：
1. 先用英语编写所有任务的指令
2. 雇佣母语者翻译成其他25种语言
3. 18种语言通过Upwork平台雇佣17名标注员
4. 7种语言通过作者人际网络招募6名志愿者
5. 所有标注员都是目标语言的母语者，具有良好的英语能力
6. 成本：每种语言$25，总计$492（包含平台费用）

**上下文生成**：
- 为每种语言收集一本开放版权的书籍
- 针插入时遵循每种语言的空格和标点规范
- 统一翻译100个名词用于公平比较

### 测试模型

**开源模型（5个）**：
- Qwen 2.5 (7B 和 72B)
- Llama 3.1 (8B)
- Llama 3.3 (70B)
- DeepSeek-R1（仅用于英语分析）

**闭源模型（2个）**：
- OpenAI o3-mini-high
- Google Gemini 1.5 Flash

**评估配置**：
- 每个任务 × 每种语言 × 每个上下文长度：50个样本
- 总计：每个任务每个模型需要5,200个提示

## 主要实验发现

### 发现1：高低资源语言的差距随上下文长度扩大

![不同上下文长度的准确率](./assets/images/Micro-accuracy%20of%20all%20models%20on%20the%20S-NIAH%20task.png)

**关键数据（S-NIAH任务）**：
- **8K上下文**：高资源语言（Top 5）与低资源语言（Bottom 5）的准确率差距为 **11个百分点**
- **128K上下文**：准确率差距扩大到 **34个百分点**
- **差距扩大趋势**：8k→32k (+21%) → 64k (+23%) → 128k (+34%)

**原因分析**：
- 长上下文扩展训练时缺乏低资源语言数据
- 长上下文能力**不能轻易跨语言迁移**
- 模型在预训练和指令微调阶段对低资源语言的暴露不足

**None选项的影响**：
- 添加"none"选项使o3-mini-high在128K英语S-NIAH上准确率下降 **32个百分点**
- 从接近100%降至约67%
- 这个简单改变让NIAH任务比RULER中困难得多

### 发现2：低资源语言即使在短上下文中也很困难

![不同模型和语言的性能](./assets/images/NIAH%20performance%20across%20models%20and%20languages%20by%20language.png)

**8K上下文表现**：
- 所有模型在高资源语言上表现优秀（>95%）
- 但在斯瓦希里语(sw)和塞索托语(st)上仍然困难
- Llama模型表现下降最严重（主要训练数据为英语）

**不同模型的语言覆盖能力**：
- **Gemini 1.5 Flash**：在塞索托语上表现出奇地好
- **Qwen 2.5 72B**：多语言支持最均衡
- **Llama系列**：在低资源语言上性能下降最严重

### 发现3：英语不是最佳语言，波兰语排名第一

![所有任务的微观准确率](./assets/images/Micro-accuracy%20across%20context-lengths%20and%20languages%20for%20all%20NIAH%20tasks.png)

**64K & 128K长上下文排名（所有模型平均）**：

1. **波兰语(pl)** - 88.0% ⭐ 最佳
2. 俄语(ru)
3. 法语(fr)
4. 意大利语(it)
5. 西班牙语(es)
6. **英语(en)** - 83.9% 🤔 仅排第6
7. ...
8. **中文(zh)** - 62.1% 😱 第4差

**令人惊讶的发现**：
- 英语和中文在大多数模型的预训练数据中占主导地位
- 但在长上下文NIAH任务上表现并不突出
- **Top 10语言**：全部来自斯拉夫、罗曼和日耳曼语系，使用拉丁或西里尔字母
- **Bottom 6语言**：包括全部4种低资源语言 + 中文 + 韩语

**可能原因**：
- 维基百科规模与性能有相关性（但不完全）
- 书写系统可能有影响（拉丁/西里尔字母 vs 表意文字）
- 中文错误主要是因为模型频繁错误地回答"none"（特别是Qwen）

### 发现4：个别模型表现差异显著

**Gemini 1.5 Flash**：
- 在所有上下文长度上都是最强模型
- 长上下文稳定性最好

**Qwen 2.5 72B**：
- 在64k和128k上显著优于Llama 3.3 70B
- 多语言能力最均衡

**o3-mini-high**：
- 平均准确率出乎意料地低
- 英语128K：67%
- 波兰语128K：92%
- 乌克兰语128K：89%
- **奇怪的行为**：错误答案的推理token数量明显多于正确答案

### 发现5：任务难度差异

![各任务性能对比](./assets/images/NIAH%20performance%20across%20models%20and%20languages%20by%20language.png)

**NIAH任务排序（从易到难）**：
1. **MQ-NIAH（多查询）** - 令人惊讶地比S-NIAH更容易（非英语）
2. **S-NIAH（单针）** - 基础任务，但none选项增加难度
3. **MK-NIAH（多键）** - 需要区分干扰项
4. **MV-NIAH（多值）** - 模型容易遗漏或提前终止
5. **NONE-NIAH（无针）** - 最难，高资源语言上表现最差

**MQ-NIAH优于S-NIAH的原因**：
- 模型在S-NIAH中更频繁地回答"none"
- MQ-NIAH的多查询结构可能提供了更多上下文线索

**CWE任务极其困难**：
- **CWE-easy**：所有模型在高资源语言上的平均准确率仅 **31.5%**
  - 8K上下文：3个模型（Llama 3.3 70B, Qwen 2.5 72B, Gemini 1.5 Flash）>80%
  - 128K上下文：性能急剧下降
- **CWE-hard**：几乎所有模型准确率接近 **0%**
- 说明LLM在长上下文聚合任务上还有巨大改进空间

### 发现6：跨语言设置中指令语言的影响巨大

![跨语言性能对比](./assets/images/The%20cross-lingual%20average%20accuracy%20of%20En%2C%20Ko%2C%20an%20Pl%20on%20NIAH%20tasks%20at%20each.png)

**实验设置**：指令语言与上下文语言不同

**关键数据**：
- **英语上下文 + 韩语指令（64K）**：准确率从91%降至71%（**下降20个百分点**）
- **韩语上下文 + 英语指令（128K）**：准确率从61%升至77%（**提升16个百分点**）

**规律总结**：
- 高资源语言的指令 + 低资源语言的上下文 = 性能下降
- 低资源语言的上下文 + 高资源语言的指令 = 性能提升
- **指令语言的选择**可能比上下文语言更重要

**位置效应**：
- 模型更擅长提取**开头和结尾**的信息
- **中间位置**的信息最难检索

### 发现7：o3-mini-high的特殊错误模式

![o3-mini的错误类型分析](./assets/images/The%20cross-lingual%20average%20accuracy%20of%20En%2C%20Ko%2C%20an%20Pl%20on%20NIAH%20tasks%20at%20each.png)

**错误类型分析（S-NIAH）**：

| 上下文长度 | o3-mini none错误占比 | 其他模型none错误占比 |
|-----------|---------------------|-------------------|
| 8K        | 59.3%              | 40.7%            |
| 32K       | 57.6%              | 42.4%            |
| 64K       | 90.2%              | 9.8%             |
| 128K      | **88.1%**          | **11.9%**        |

**关键发现**：
- o3-mini在超长上下文中倾向于**过度保守**
- 128K时，88.1%的错误是错误地回答"none"（明明答案存在）
- 只有11.9%是其他类型错误
- 其他模型的错误分布相对均衡

**推理行为异常**：
- 错误答案的推理token数量 **> 正确答案的推理token数量
- 说明推理行为高度低效
- 对简单检索任务进行了不必要的复杂推理

**DeepSeek-R1的策略**：
- 采用系统化策略：按章节划分上下文
- 同时进行摘要和目标搜索
- 在英语任务上整体性能优秀

## 技术洞察与挑战

### 长上下文的核心挑战

#### 1. 位置偏见（Position Bias）
- **现象**：模型更擅长提取开头和结尾的信息
- **问题**：中间位置的信息最容易被"忽略"
- **原因**：注意力机制的固有局限性
- **影响**：在真实应用中，关键信息可能出现在任何位置

#### 2. 语言资源不平衡
- **训练数据差异**：预训练和指令微调阶段的语言分布
- **长上下文训练数据**：可能主要使用高资源语言
- **迁移能力有限**：长上下文能力不能轻易跨语言迁移
- **后果**：低资源语言在长上下文中"丢失"信息更快

#### 3. 注意力稀释效应
- **机制**：上下文越长，每个token分配到的注意力越少
- **后果**：关键信息可能被"淹没"在海量文本中
- **测量**：准确率随上下文长度的下降趋势
- **对策**：需要更高效的长上下文注意力机制

#### 4. None选项的困境
- **真实性**：反映真实场景中问题可能无答案
- **难度提升**：使准确率显著下降（最高32个百分点）
- **模型行为**：部分模型过度保守，部分模型过度自信
- **训练问题**：可能在NIAH数据（不含none选项）上过拟合

#### 5. 分词器差异
- **不公平性**：不同模型对同一文本的token数量差异巨大
  - 例如：泰米尔语文档在Gemini上42,124 tokens，在Qwen上103,990 tokens
- **选择困境**：
  - 方案1：相同文本，不同token数
  - 方案2：相同token数，不同文本量
- **论文选择**：方案2（专注序列长度影响）
- **相关性**：两种设置下模型排名的Kendall's τ = 0.82

### 常见错误模式分析

#### NIAH任务错误
1. **过度保守**：错误地回答"none"（特别是o3-mini）
2. **返回干扰项**：特别在MK-NIAH和NONE-NIAH中
3. **不完整答案**：
   - MQ-NIAH：只返回一个needle而非两个
   - MV-NIAH：遗漏4个value中的部分
4. **数字循环**：Llama和Qwen小型模型会重复数字或递增
5. **语言混淆**：Qwen 2.5 7B和LlaMa 3.1 8B在处理波兰语时混入其他语言

#### CWE任务错误
1. **不完整列表**：只返回前8-9个高频词
2. **幻觉答案**：返回不在文本中的通用高频词（如"the", "and"）
3. **重新定义任务**：自行解释任务而非执行
4. **推理溢出**：o3-mini和DeepSeek-R1超出输出token限制

#### 特殊语言问题
- **中文**：Qwen频繁错误回答"none"
- **波兰语**：小型模型容易混入其他语言
- **德语/日语**：有时基于上下文而非needle创造答案

## 实际应用启示

### 模型选择指南

#### 场景1：多语言文档处理
- **任务类型**：翻译、摘要、信息提取
- **推荐模型**：
  1. Gemini 1.5 Flash（最佳选择）
  2. Qwen 2.5 72B（成本效益最佳）
- **原因**：
  - 多语言支持全面
  - 长上下文稳定性好
  - 高低资源语言表现均衡

#### 场景2：英语为主的长文本分析
- **任务类型**：学术论文分析、法律文档审查
- **推荐模型**：Gemini 1.5 Flash
- **原因**：
  - 在英语长上下文上表现最佳
  - 128K仍保持高准确率
  - 适合专业领域应用

#### 场景3：特定高资源语言（如波兰语、俄语）
- **推荐模型**：几乎所有主流模型都表现良好
- **注意**：波兰语在长上下文上竟然是最佳语言
- **建议**：优先考虑斯拉夫、罗曼、日耳曼语系语言

#### 场景4：低资源语言处理
- **挑战**：所有模型在低资源语言上性能显著下降
- **推荐策略**：
  1. 使用Qwen 2.5 72B或Gemini 1.5 Flash
  2. **控制上下文长度**：尽量≤32K
  3. **采用分段处理**：将长文档切分
  4. **跨语言提示**：使用英语指令 + 目标语言上下文
- **权衡**：准确性 vs 上下文长度

#### 场景5：边缘设备或资源受限
- **推荐模型**：Qwen 2.5 7B
- **限制条件**：
  - 上下文长度≤32K
  - 主要支持高资源语言
  - 避免波兰语等特殊语言（可能出现语言混淆）
- **替代方案**：使用API调用更大模型

#### 场景6：需要高准确性的检索
- **避免依赖**：不要过度依赖none选项
- **策略**：
  - 如果可能，使用不含none选项的提示
  - 或接受准确率会下降20-30%
- **模型选择**：Gemini 1.5 Flash受none影响最小

#### 场景7：聚合和计数任务
- **现实**：所有当前模型在CWE-hard上都表现糟糕
- **建议**：
  - 避免在生产环境中依赖LLM进行精确计数
  - 考虑结合传统方法（如正则表达式、脚本）
  - 或使用专门的工具进行预处理

### 跨语言应用策略

#### 策略1：优先使用高资源语言指令
- 即使上下文是低资源语言，也使用英语/高资源语言编写指令
- 可提升10-20个百分点的准确率

#### 策略2：上下文分段
- 将超长上下文（>64K）切分成多个片段
- 分别处理后合并结果
- 特别适用于低资源语言

#### 策略3：混合方法
- 使用传统方法定位候选区域
- LLM只处理相关片段
- 降低对长上下文能力的依赖

## 研究意义与未来方向

### 学术价值

1. **揭示真实差距**
   - 打破"所有模型都能处理长上下文"的假象
   - 量化了语言资源对长上下文能力的影响
   - 发现英语不是最佳语言的反直觉结果

2. **基准测试贡献**
   - 提供首个大规模多语言长上下文基准
   - None选项使任务更接近真实场景
   - 为未来研究提供标准化评估工具

3. **跨语言理解**
   - 系统研究了指令语言和上下文语言的交互
   - 揭示了位置偏见和注意力稀释效应
   - 为跨语言训练策略提供insights

### 对模型开发的启示

1. **训练数据平衡**
   - 需要在长上下文训练中包含更多低资源语言
   - 不能假设长上下文能力会自动跨语言迁移
   - 考虑语言特定的长上下文微调

2. **任务设计改进**
   - 训练时应包含"无答案"场景
   - 避免在synthetic NIAH数据上过拟合
   - 开发更好的None识别能力

3. **架构优化方向**
   - **位置编码**：改进中间位置信息的检索能力
   - **注意力机制**：设计更高效的长上下文注意力
   - **自适应策略**：根据上下文长度动态调整处理方式

4. **分词器考虑**
   - 开发对多语言更公平的分词器
   - 考虑字节级别的评估标准化
   - 减少语言间token数量的差异

### 产业应用影响

1. **现实预期管理**
   - 不要宣称模型有128K能力就认为它在所有语言上都有效
   - 需要针对具体语言和任务进行评估
   - 对低资源语言设定合理预期

2. **系统设计考虑**
   - 根据语言选择合适的上下文长度
   - 实现智能上下文管理策略
   - 考虑混合方法而非纯LLM方案

3. **多语言公平性**
   - 关注语言公平性，不只优化英语
   - 为全球用户提供一致的体验
   - 投资低资源语言的数据收集和模型优化

### 未来研究方向

1. **扩展语言覆盖**
   - 增加更多低资源语言
   - 研究语言类型学特征的影响
   - 探索代码混合和方言

2. **真实任务评估**
   - 结合synthetic和realistic benchmarks
   - 开发特定领域的长上下文测试
   - 评估生成质量而非仅检索准确率

3. **训练方法创新**
   - 多语言长上下文联合训练
   - 跨语言迁移学习
   - 高效的长上下文微调方法

4. **评估标准化**
   - 字节级别的评估标准
   - 考虑认知负荷的评估指标
   - 成本-效益分析框架

## 相关链接

- [论文原文](https://arxiv.org/pdf/2503.01996)
- [GitHub仓库](https://github.com/mungg/OneRuler)
- [Kcores LLM Arena](https://llm-arena.kcores.com)
